```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = FALSE)
library(tidyverse)
library(ggplot2)
library(knitr)
library(kableExtra)
library(extraDistr)
library(gridExtra)
library(latex2exp)
library(moments)
```

```{r, include=FALSE}
paygap <- read.csv('./data/gender-paygap-2019.csv')
paygap <- paygap %>%
  mutate(EmployerSize = factor(EmployerSize, levels = c('0-249','250-499','500-999','1000-4999','5000-19999','20000+')))
nycheat <- read.csv('./data/nyc-heatwave.csv')
```

\newcommand{\E}{\text{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\SD}{\text{SD}}
\newcommand{\SE}{\text{SE}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Cor}{\text{Cor}}
\renewcommand{\P}{\text{P}}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\sumin}{\sum_i^n}
\newcommand{\Bias}{\text{Bias}}

\ 

# 12--1 Point and Interval Estimators

A **point estimator** is a *single* plausible value for an unknown population parameter. Any point statistic derived from a sample (e.g. the sample mean, $\bar X$) is a point estimator.  

An **interval estimator** is a *range* of plausible values for an unknown parameter. Two common interval estimators are **confidence intervals** (a frequentist method) and **credible intervals** (a Bayesian method).   



\ 

# 12--2 Confidence Intervals

A confidence interval is a range of values, computed from a sample of data, that has an approximate probability of containing the true parameter. Confidence intervals are often more useful than point estimators as they provide a reasonable margin of error when estimating an unknown parameter.  

Just as the sample mean is a point estimate of the true mean, a _95\% confidence interval for the mean_ is an interval estimate of the true mean, and can be expressed as follows: 

$$\P(LB \leq \mu \leq UB) = 0.95$$

where $LB$ and $UB$ are the lower and upper bounds of the 95\% confidence interval.  

Note that since confidence intervals are computed from sample data, they are still *estimators*; thus for any given interval the 95\% confidence level is only an *approximate* proabibility that the interval contains the true parameter.  



\ 

# 12--3 A Confidence Interval for a Mean

Theoretically you can compute a confidence interval for any parameter, e.g. the median, max, min, etc. Mostly in statistics we're interested in the mean, and so in this section we'll show how to compute a confidence interval for a mean.  

Computing the bounds of a confidence interval requires that you know the distribution of the parameter in question. If you are computing a confidence interval for a mean, you can wield the central limit theorem to your advantage. Recall the CLT says that the sample mean follows a normal distribution with mean $\mu$ and variance $\frac{\sigma^2}{n}$:

$$\bar X \sim \mathcal N \bigg( \mu, \frac{\sigma^2}{n} \bigg)$$

Since the sample mean follows a normal distribution, you can visualize a 95\% confidence interval for the mean as follows:  

```{r, echo=FALSE, fig.width = 5, fig.height=3.5, fig.align='center'}
mu = 0; sigma = 1

x = seq(-4, 4, length = 1000) * sigma + mu
y = dnorm(x, mu, sigma)

df = data.frame(x = x, y = y)


ggplot(data = df, mapping = aes(x = x, y = y)) +
  geom_line() +
  scale_x_discrete(name = TeX('$\\mu$'), 
                   breaks = c(-3:3), 
                   labels = c('-3SE','-2SE','-SE',' ','+SE','+2SE','+3SE'), 
                   limits = c(-3:3)) +
  scale_y_continuous(limits = c(0,0.45)) +
  ylab('probability') + 
  ggtitle(TeX('Distribution of $\\bar{X}$')) + 
  geom_area(aes(x = ifelse(x > -1.96 & x < 1.96, x, 0)), fill='violetred', alpha=0.4) +
  geom_segment(x = -1.96, xend = -1.96, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') + 
  geom_segment(x = 1.96, xend = 1.96, y = 0, yend = 0.1, color = 'violetred', linetype = 'dotted') +
  geom_text(label = 'p = 0.95', x = 0, y = 0.15, size = 6, color = 'violetred') +
  geom_text(label = 'LB', x = -1.96, y = 0.12, size = 4, color = 'violetred') +
  geom_text(label = 'UB', x = 1.96, y = 0.12, size = 4, color = 'violetred') +
  theme_classic()
```

where $\SE = \frac{\sigma}{\sqrt n}$. In the above graph the shaded region represents the range of values contained by a 95\% confidence interval.  

In estimation problems the **significance level**, denoted $\alpha$, is the probability the true parameter lies *outside* the confidence interval. For a 95\% confidence interval, $\alpha =$ 0.05.  

Since the interval is symmetric, its lower and upper bounds lie at the $Z$-statistics corresponding to the 2.5th and 97.5th percentiles of the distribution (i.e. $Z_{\alpha/2}$ and $Z_{(1- \alpha/2)}$). These values are: 

```{r}
c(qnorm(0.025), qnorm(0.975))
```

i.e. a 95\% confidence interval will have a lower and upper bound 1.96 standard errors from the mean (provided the data is normally distributed).   

If the true mean and standard deviation are unknown (as is usually the case), and you are using the $t$-distribution to approximate the sample mean, the lower and upper bounds of the 95\% confidence interval lie at $t$-statistic corresponding to the 2.5th and 97.5th percentiles of the $t$-distribution (i.e. $t_{\alpha/2}$ and $t_{(1- \alpha/2)}$) with the appropriate degrees of freedom. For DoF = 30, these values are:  

```{r}
c(qt(0.025, df = 30), qt(0.975, df = 30))
```

i.e. if the mean follows a $t$-distribution with 30 DoF, a 95\% confidence interval will have a lower and upper bound 2.04 standard errors from the mean.  

In general, a confidence interval for the mean can be written:

$$\bar X - c \cdot SE \leq \mu \leq \bar X + c \cdot SE$$

where $c$ is the test statistic (a measure of how far away the lower and upper bounds are from the mean in units of standard error). The value of $c$ depends on:

- the confidence level ($1-\alpha$)
- which distribution you are using to approximate the mean

If data follows a normal distribution, a confidence interval for the mean can be expressed:

$$\bar X - Z \cdot \frac{\sigma}{\sqrt n} \leq \mu \leq \bar X + Z \cdot \frac{\sigma}{\sqrt n}$$

where $Z$ is the $Z_{(1-\alpha/2)}$-statistic of a normal distribution.  

If data follows a t-distribution, a confidence interval for the mean can be expressed: 

$$\bar X - t \cdot \frac{s}{\sqrt n} \leq \mu \leq \bar X + t \cdot \frac{s}{\sqrt n}$$

where $t$ is the $t_{(1-\alpha/2)}$-statistic of a $t$-distribution with $n-1$ degrees of freedom.  

Generally for sample data you should use the $t$-distribution, since the true mean and s.d. of the population are unknown. However for large $n$ it doesn't make much difference, and you can use the normal distribution with plug-in estimates in place of $\mu$ and $\sigma$.  

## Computing the bounds in practice 

In the pay gap data, the variable `DiffMeanHourlyPercent` has a sample mean $\bar X =$ 12.356, a sample s.d. $s =$ 16.009, and a sample size $n =$ 153.  

```{r, include=FALSE}
#c(mean(paygap$DiffMeanHourlyPercent), sd(paygap$DiffMeanHourlyPercent), length(paygap$DiffMeanHourlyPercent))
```

Suppose we want to compute a 95\% confidence interval for the true mean difference in hourly wages. Since $n > 30$, we can assume the sample mean is approximately normal with:

$$\bar X \sim \mathcal N \bigg( \bar X, \frac{s}{\sqrt n} \bigg) \;\;\; \Longrightarrow \;\;\; \bar X \sim \mathcal N \bigg( 12.356, \frac{16.009}{\sqrt{153}} \bigg)$$

where we have used the CLT with sample values as plug-in estimates. The general form of the confidence interval is:

$$\bar X - c \cdot \frac{s}{\sqrt n} \leq \mu \leq \bar X + c \cdot \frac{s}{\sqrt n}$$

Since we are using the normal distribution to approximate the data, $c$ in this case is the $Z_{0.975}$-statistic of a standard normal distribution. This is:

```{r}
qnorm(0.975)
```

Substituting the values above as plug-in estimates, we get the following confidence interval for the mean: 

$$
\begin{aligned}
  12.36 - 1.96 \cdot \frac{16.01}{\sqrt{153}} \leq \; &\mu \leq 12.36 + 1.96 \cdot \frac{16.01}{\sqrt{153}}
  \\ 
  \\
  \Longrightarrow \hspace{0.5cm} 9.82 \leq \; &\mu \leq 14.90
\end{aligned}
$$

Note if we had used a $t$-distribution to approximate the data (which, strictly speaking we should have, since $\mu$ and $\sigma$ are unknown), $c$ would be the  $t_{0.975}$-value of a $t$-distribution with 152 degrees of freedom. This is:

```{r}
qt(0.975, df = 152)
```

Substituting these values gives the following confidence interval: 

$$
\begin{aligned}
  12.36 - 1.976 \cdot \frac{16.01}{\sqrt{153}} \leq \; &\mu \leq 12.36 + 1.976 \cdot \frac{16.01}{\sqrt{153}} \\ 
  \\ 
  \Longrightarrow \hspace{0.5cm} 9.80 \leq \; &\mu \leq 14.92
\end{aligned}
$$

This interval is only trivially different to the one computed using the normal distribution, since $n$ in this case is large. 

But if, for instance, we had only 10 observations in our data, and we had used a $t$-distribution with 9 DoF, note how $c$ is more substantially different: 

```{r}
qt(0.975, df = 9)
```

This gives a confidence interval: 

$$9.48 \leq \mu \leq 15.24$$

Thus when $n$ is large, it's sufficient to use the normal distribution to compute confidence intervals (with the appropriate plug-in estimates), since the difference between the $t$ and normal distributions is trivial for large $n$. But when dealing with small samples, you must use the $t$-distribution. 

## A function for calculating confidence intervals 

Currently there is no function in R to compute a confidence interval from a given array of data. You either have to perform the computations manually (as demonstrated above) or write a function yourself.   

Below is an example of a user-defined function^[For more on writing user-defined functions in R, go <a href="https://www.statmethods.net/management/userfunctions.html">here</a>.]   that can perform all the required computations for a confidence interval for a mean: 

```{r}
confidence_interval = function(data, conflevel) {
  n = length(data)           # sample size 
  xbar = mean(data)          # sample mean 
  SE = sd(data) / sqrt(n)    # standard error
  alpha = 1 - conflevel      # alpha
  
  lb = xbar + qt(alpha/2, df = n-1) * SE    # lower bound
  ub = xbar + qt(1-alpha/2, df = n-1) * SE  # upper bound
  
  cat(paste(c('sample mean =', round(xbar,3), '\n', 
              conflevel*100, '% confidence interval:', '\n', 
              'lower bound =', round(lb,3), '\n', 
              'upper bound =', round(ub,3))))
}
```

Running this code will define a new function in the environment, `confidence_interval()`, that takes two arguments: `data`, a vector array of numeric data, and `conflevel`, the desired confidence level. It then computes a confidence interval for the mean at the desired confidence level.  

You can use this function to compute a 95\% confidence interval for the mean difference in hourly wages:  

```{r}
confidence_interval(paygap$DiffMeanHourlyPercent, 0.95)
```

A 99\% confidence interval for the same parameter:

```{r}
confidence_interval(paygap$DiffMeanHourlyPercent, 0.99)
```



\ 

# 12--4 Misconceptions About Confidence Intervals

It's important to remember that confidence intervals are computed from sample data. This means that different samples of data will yield different confidence intervals, as is the case for point estimates. This is why the confidence level describes only the *approximate* probability the interval contains the true parameter. For any given interval, it either contains the true parameter or it doesn't; there is no way to tell which.   

Recall from chapter 7 that *probability* refers to the relative frequency of an event in a large number of trials.^[In the frequentist view, anyway.] Thus the *true* interpretation of a 95\% confidence interval is as follows:  

_**A 95\% confidence interval is a range of values where, if you repeated the experiment many times, approximately 95\% of the confidence intervals generated will contain the true parameter.**_  

This is the "proper" definition of a confidence interval. It's important to understand what a confidence interval is not: 

- a 95\% confidence interval does not mean that for a given interval, there is exactly a 95\% probability the true parameter lies in the interval. 
- a confidence interval is not a definitive range of of plausible values for the true parameter. 
- a 95\% confidence interval does not guarantee there is a 95\% probability the sample statistic from a subsequent experiment will fall in the interval specified.  

Confidence intervals exhibit variability across different samples, in the same way that point estimates do. The following code demonstrates this by generating 20 random samples and plotting a 95\% confidence interval for the mean based on each sample. The pink line is the true mean of the population.  

```{r, fig.width=5, fig.height=3.5, fig.align='center'}
set.seed(12)

box = c(1,1,1,5)
n = 50
X = sample(box, n, replace = TRUE)
Xbar = mean(X)
SE = sd(X)/sqrt(n)
c = qt(0.975, n-1)

experiment = function() {
  X = sample(box, n, replace = TRUE)
  Xbar = mean(X)
  SE = sd(X)/sqrt(n)
  c(Xbar - c*SE, Xbar + c*SE)
}

CIs = data.frame(t(replicate(20, experiment())))
names(CIs) = c("lower", "upper")
CIs$SampleNumber = 1:20

ggplot() + 
  geom_errorbar(data = CIs, aes(x = as.factor(SampleNumber), ymin = lower, ymax = upper)) +
  geom_hline(yintercept = 2, color = 'violetred') + 
  coord_flip() + theme_classic() + ylab('95% confidence interval') + xlab('sample number')
```

i.e. there is clear variability in the confidence intervals across the samples. Note that one of the 20 intervals does not contain the true mean (sample #10). This is a clear illustration of the 95\% probability associated with the interval: across 20 different samples we expect that only 95\% of the intervals *actually* contain the true mean.  

In general, without knowing the true parameter, there is no way to know whether a confidence interval generated from a *particular* sample actually contains the true parameter or not.  

Nontheless, confidence intervals are still useful in estimation, since they provide a wider range of plausible values for the true parameter than a point estimate does, and they can characterize the uncertainty in an estimate.  


\ 
