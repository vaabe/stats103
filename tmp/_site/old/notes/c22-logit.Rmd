```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = FALSE)
library(tidyverse)
library(ggplot2)
library(knitr)
library(kableExtra)
library(extraDistr)
library(gridExtra)
library(latex2exp)
library(moments)
library(bookdown)
library(rsconnect)
library(tufte)
```

```{r, include=FALSE}
paygap <- read.csv('./data/gender-paygap-2019.csv')
paygap <- paygap %>%
  mutate(EmployerSize = factor(EmployerSize, levels = c('0-249','250-499','500-999','1000-4999','5000-19999','20000+')))
nycheat <- read.csv('./data/nyc-heatwave.csv')
```

\newcommand{\E}{\text{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\SD}{\text{SD}}
\newcommand{\SE}{\text{SE}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Cor}{\text{Cor}}
\renewcommand{\P}{\text{P}}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\sumin}{\sum_i^n}
\newcommand{\Bias}{\text{Bias}}

---

# 22--1 Logistic Regression 

Logistic regression (or logit) is a regression technique for when the outcome variable is binary.   

In logistic regression the goal is to predict $\P(Y=1|X=x)$, where $X$ is the predictor. Although the outcome variable is either 0 or 1, the *predicted* outcome will be a probability, so it can be anything between 0 and 1.   

Complication: to get a linear model, we need to do a non-linear transformation of $\P(Y=1|X=x)$, using what's known as a “logit” or “log-odds” function.   

If we let $p(x) = \P(Y=1|X=x)$, then the logistic regression model has the following functional form:

$$\ln \bigg(  \frac{p(x_i)}{1-p(x_i)} \bigg) = \beta_0 + \beta_1 x_{i1} + ... + \beta_k x_{ik} + \varepsilon_i$$

where the LHS is the logit function, and the RHS is a linear function of the predictors, just like in OLS regression. 

Another complication: the regression coefficients. In logit models the regression coefficients represent *log-odds* ratios. If we exponentiate the coefficients (which we usually do), we get an *odds-ratio*, which represents the likelihood of outcome variable being a success ($Y=1$) given the predictor.   

If you're interested, the next section gives an example of a logit model used in a real study on the effects of language on economic decision-making.  



\ 

# 22--2 Linguistic Determinism? A Study 

A study by Keith Chen in 2013 tested a “linguistic-savings hypothesis”, whether grammatical differences in languages affect intertemporal choice and economic decision-making.^[Read the original study <a href="./downloads/chen-language.pdf" download>here</a>.] Chen investigated whether Strong FTR languages (i.e. ones that grammatically ‘mark’ the future) cause speakers to discount the future more than Weak FTR languages (i.e. ones that do not grammatically mark the future), and whether this behavioural difference is manifest in individual savings behaviour. His study concluded that the distancing mechanism inherent in Strong FTR languages does indeed significantly lower the probability that an individual will take future-oriented actions. 

First, a quick note on language:   

A Strong FTR language is one that grammatically 'marks' the future (with a word, or a set of words, etc.). English and French are two such examples:  

- English: "it *will* rain tomorrow"  
- French: "il *va* pleuvoir demain" (it will rain tomorrow)

Weak FTR languages do not grammatically mark the future in this manner; often in such languages the present tense form of the verb is used, and the notion of future time is gleaned rather from context than grammatical markers. German and Finnish are two examples:  

- German: "Morgen regnet es" (it rains tomorrow)  
- Finnish: "Huomenna sataa" (tomorrow rains)  

Since saving money is a future-oriented activity, Chen claimed the distancing mechanism in Strong FTR languages causes people to (unwittingly) save less money. In his study, Chen found a significant difference in savings behaviour between speakers of Strong FTR and Weak FTR languages, even when controlling for a number of individual and country variables.  

Chen used a logit model to estimate the probability than an individual will save money, based on whether they speak a Strong or Weak FTR language:

$$\P(\text{save}_{it}) = \frac{\exp(Z_{it})}{1 + \exp(Z_{it})}$$

where $\text{save}_{it}$ is a binary outcome variable (either the individual saved money (1) or did not save money (0) during a particular year). The logit model is:

$$Z_{it} = \beta_{0} + \beta_{1} \text{StrongFTR} + \beta_{2} X_{it} + \beta_{3} X_{t} + \beta_{4} F_{it}^{ex} + \beta_{5} F_{t}^{c}$$

where $\text{StrongFTR}$ is the variable of interest, and the other predictors serve as various individual and country-level control variables.   

Below is a crude reimplementation of the main logit model in the study.^[Download the data <a href="./data/chen-language.csv" download>here</a>.] We can use the `glm()` function from the `stats` package to perform logistic regression.  

```{r,include=FALSE}
ccdata = read.csv('./data/chen-language.csv') %>% rename(StrongFTR = PredictionFTR)
```


```{r}
library(stats)
library(alpaca)

## simple logit regression
reg1 = glm(SavedThisYr ~ StrongFTR,
             data = ccdata, family = binomial(link = 'logit'))

## model summary
summary(reg1)
```

The code above performs a simple logistic regression of the binary outcome, `SavedThisYr`, on the main predictor of interest, `StrongFTR` (also a binary variable, coded 1 if the language is classified Strong FTR, 0 if the language is classified Weak FTR). The coefficient on StrongFTR is -0.7871. This is the log-odds ratio. To make this number more meaningful, we exponentiate the model coefficients, as follows:

```{r}
## odds-ratio 
exp(coef(reg1))
```

These numbers are odds-ratios. They say that, based on the data in the study, people who speak Strong FTR languages are on average only 45\% as likely to save money that year than people who speak Weak FTR languages. This was indeed Chen's main conclusion in the study.  

It's a bold claim. Many have contested the validity of Chen's study, claiming (with good reason) that he did not properly isolate (or even identify) the causal effect in his study. Read a critical response to Chen's study here: https://dlc.hypotheses.org/360.  

Nevertheless, it's still an interesting result. Chen managed to show that the coefficient on `StrongFTR` manages to hold even after using a number of individual and country-level control variables.  

The following model adds control variables for a country's legal system, its log GDP per capita, the log GDP growth rate, the unemployment and interest rates, and a number of individual (age, gender) and regional (country, continent) variables: 

```{r}
## logistic regression with controls
reg6 = feglm(SavedThisYr ~ StrongFTR + LegalFr + LegalGe + LegalSc + logPCGDP
              + Growth_PCGDP + Unemployed + RealIntRate + LegalRightsIndex + TrustMostPpl + 
                FamilyImp + AvgTrust + AvgFamilyImp + LanguageShare + FTRShare | 
                AgeCat + Sex + Continent, data = ccdata, family = binomial(link = 'logit'))

## model summary
summary(reg6)

## log-odds ratios
exp(coef(reg6))
```

As you can see, the coefficient on StrongFTR maintains its value, even after adding these controls.  




\ 

--- 

\ 

\ 







