---
title: 'chapter 7 Elements of Probability'
output:
  tufte::tufte_html:
    tufte_features: ['fonts','background','italics']
    css: '../mytufte.css'
    toc: true
    toc_depth: 2
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
link-citations: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = FALSE)
library(tidyverse)
library(knitr)
library(gridExtra)
library(extraDistr)
library(moments)
library(latex2exp)
library(tufte)
```

\newcommand{\E}{\text{E}}
\newcommand{\Var}{\text{Var}}
\newcommand{\SD}{\text{SD}}
\newcommand{\SE}{\text{SE}}
\newcommand{\Cov}{\text{Cov}}
\newcommand{\Cor}{\text{Cor}}
\renewcommand{\P}{\text{P}}
\newcommand{\pd}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\sumin}{\sum_i^n}
\newcommand{\Bias}{\text{Bias}}

---

# 7--1 Wherefore Probability? 

Statistical inference is based on ideas from probability theory. Discussion of probability was mostly avoided in Part I--this was in a bid to visually demonstrate the power and relevance of statistical methods, while unencumbered by (arduous) theory. Of course, in order to actually understand these methods you'll need some of the formalism--thus these three chapters are intended to introduce some of the basic ideas of probability behind statistical inference. 



\ 

# 7--2 Random Processes

You can think of a random process as anything that gives rise to an **outcome**. Tossing a coin or rolling a die are two classic examples.  

In fact, many experiments/phenomena can be modeled as random processes--even ones whose outcomes are seemingly nonrandom. E.g.--whether the stock market will go up or down tomorrow, or whether a certain candidate will win an election, or whether the sun will rise tomorrow--can be thought of as random processes in the sense that there will *necessarily* be an outcome, even if the outcome may appear to have a deterministic bent.     

Broadly speaking, **probability** is a measure that quantifies the likelihood that a certain outcome (or set of outcomes) will occur. Though there are many ways to interpret probability^[Click <a href="https://plato.stanford.edu/entries/probability-interpret/">here</a> for more.], most modern applications use the mathematical formalism developed last century, which defines probability in terms of an underlying **probability space** that gives rise to a set of axioms (see below).  



\ 

# 7--3 Probability Spaces 

Probability spaces are used to model random processes. They have three components:  

- $\Omega$, a **sample space**, which is the set of all possible outcomes for the process
    + e.g. if you toss a coin twice: $\Omega = \{ HH, HT, TH, TT \}$  
- $\mathcal F$, a **set of events**, that make up all possible subsets of the sample space
    + e.g. $\mathcal F = \{ \text{getting 1 head, getting 2 heads, ...} \}$
- $P$, a **probability function**, that assigns probabilities to each event
    + e.g. the probability of getting 2 heads: $\P(\text{ 2 heads }) = \frac 14$ 
    
A coin toss is an example of a process with a **discrete** sample space, since its outcomes are countable and finite. Of course, many processes have uncountably infinite sample spaces: e.g. say you are measuring the high temperature on a certain day--the sample space in this case would be the set of all real numbers.   

In R you can simulate a random process using the `sample()` function. You must specify the sample space, the sample size, and whether you want to sample with replacement or not.  

E.g. to simulate tossing a coin twice:

```{r}
sample(x = c('H','T'), size = 2, replace = TRUE)
```

Naturally this is one of four possible outcomes for this process.  

\ 

# 7--4 Some Probability Axioms 

When you define the outcomes of a random process in terms of a probability space, there are a convenient set of axioms for probability that naturally follow. 

## The complement rule 

Naturally, the probabilities of all possible events must sum to 1. E.g. if $\P(A)$ denotes the probability that event $A$ happens, then the probability of $A$ *not* happening is:

$$\boxed{ \P(A^c) = 1 - \P(A) }$$

where $A^c$ is the complement of event $A$.  

## Conditional probability

For two events, $A$ and $B$ (both from the set of events $\mathcal F$), the probability that $A$ occurs given that $B$ has already occurred is:

`r margin_note("If you're unfamiliar with set notation, <a href='https://www.onlinemathlearning.com/set-notation.html'>look into it</a>. For reference:")`

`r margin_note("$\\text{P} (A \\; | \\; B)$ means the conditional probability of $A$ given $B$.")`

`r margin_note("$\\text{P} (A \\cap B)$ means the probability that both $A$ and $B$ occur.")`

$$\boxed{ \P(A \; | \; B) = \frac{\P(A \cap B)}{\P(B)} }$$

The RHS of this equation essentially restricts the sample space of $A$ and $B$ to only those outcomes where $B$ occurs.   

## The multiplication rule 

Rearranging the law of conditional probability gives the **multiplication rule:**

$$\boxed { \P(A \cap B) = \P(A \; | \; B) \; \P(B) }$$

i.e. the probability that two events both happen equals the probability the first will happen, multiplied by the probability the second will happen given the first has happened.  

## Independence

Two events are independent if the occurrence of one has no effect on the probability that the other occurs.  

If events $A$ and $B$ are independent:

$$\boxed { \P(A \; | \; B) = \P(A) } \hspace{0.5cm} \text{(if independent)}$$

i.e. the probability that $A$ occurs is invariant to whether $B$ has occurred or not.  

This gives the **multiplication rule for independent events**: 

$$\boxed{ \P(A \cap B) = \P(A) \; \P(B) } \hspace{0.5cm} \text{(if independent)}$$

i.e. if two events are independent, the probability they both happen is simply the product of their individual probabilities. 

## Mutual exclusivity

Two events are **mutually exclusive** or **disjoint** if they cannot both happen.  

If $A$ and $B$ are mutually exclusive, then if $A$ happens, $B$ cannot also happen:

$$\boxed{ \P(A \cap B) = 0} \hspace{0.5cm} \text{(if mutually exclusive)}$$


## The addition rule

This leads to the **addition rule:** for two mutually exclusive events $A$ and $B$, the probability that at least one will happen:  

`r margin_note("where $\\P(A \\cup B)$ denotes the probability that either $A$ or $B$ will happen.")`

$$\boxed { \P(A \cup B) = \P(A) + \P(B) } \hspace{0.5cm} \text{(if mutually exclusive)}$$

It should also follow that if $A$ and $B$ are *not* mutually exclusive (i.e. $\P (A \cap B \neq 0)$ ), then the probability that at least one will happen is:

$$\boxed{ \P(A \cup B) = \P(A) + \P(B) - \P(A \cap B) }$$


## The law of total probability

Given two events in the event space, $A$ and $B$, the probability that $A$ occurs can be written:

$$\P(A) = \P(A \cap B) + \P(A \cap B^c)$$

i.e. the probability that $A$ occurs equals the probability that $A$ and $B$ both occur, plus the probability that $A$ occurs and $B$ doesn't occur.   

Using the definition of conditional probability, you can also write this as:  

$$\P(A) = \P(A \; | \; B) \; \P(B) + \P(A \; | \; B^c) \; \P(B^c)$$

You can generalize this formula for event spaces with multiple events: 

$$\boxed{ \P(A) = \sum_i \P(A \cap B_i) = \sum_i \P(A \; | \; B_i) \; \P(B_i) }$$

where $B_i = \{B_1, B_2, ... \}$ is a general partition of the sample space.  

\ 

# 7--5 Two Interpretations of Probability 

The probability rules introduced above are part of the mathematical axiomatisation of probability introduced last century. Though they are useful for calculating probabilities in well-defined sample spaces, the concept of probability itself--and how exactly to define it--is a philosophical one that has seen many interpratations over the past centuries. Right now there are two interpretations of probability that preside--the frequentist approach and the Bayesian approach. Each treats the concept of probability differently.  

## The frequentist approach 

The frequentist interpretation of probability is certainly the most common--not only in applied fields but also in the everyday parlance surrounding probability.  

These are the main tenets of the frequentist approach: 

- probability is defined in terms of an event's relative frequency in a large number of trials  
- e.g. if you conduct $n$ trials, and $k$ is the number of trials in which event $X$ occurs, the probability of event $X$ is defined as: 

$$\P(X) \approx \frac kn$$

- the frequentist approach assumes that data is a repeatable random sample, and if the experiment is repeated many times, the relative frequency of an event will converge to its true probability:

$$\P(X) = \lim_{n \rightarrow \infty} \frac kn$$

E.g. the reason we "know" that the probability of a coin toss yielding heads is one half--if indeed we really know this at all--is because when you run the process many times, the proportion of observed heads empirically converges to one half.  

You can demonstrate this in R:

```{r}
cointoss = sample(x = c('H','T'), size = 100000, replace = TRUE)

prop.table(table(cointoss))
```

The output shows that of the 100,000 tosses, almost exactly half were heads and half were tails. If you conclude from this that the probability of landing heads is a half, you have used the frequentist interpretation of probability.  

The frequentist approach doesn't conflict with the mathematical axioms of probability introduced above--it only provides a "way" to interpret probability and apply these axioms to real-world processes.  

## The Bayesian approach 

`to be added`

\ 

---

\ 

\ 



